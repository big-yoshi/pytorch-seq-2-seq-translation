{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq translation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmxdUhTu3nPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8rS0qjm4KHf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "0bb4de9a-bbac-49e9-cd39-abb958a79896"
      },
      "source": [
        "! wget https://download.pytorch.org/tutorial/data.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-08 16:54:54--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 99.86.38.72, 99.86.38.37, 99.86.38.96, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|99.86.38.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip            100%[===================>]   2.75M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-09-08 16:54:54 (56.9 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvxpRTGL4gZG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "044076d6-6a88-478a-b3aa-8d624933b31e"
      },
      "source": [
        "! unzip data*"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkeojKNH4tBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {0:'SOS',1:\"EOS\"}\n",
        "    self.n_words = 2\n",
        "  \n",
        "  def addSentence(self, sentence):\n",
        "    for word in sentence.split(' '):\n",
        "      self.addWord(word)\n",
        "  def addWord(self, word):\n",
        "    if word not in self.word2index:\n",
        "      self.word2index[word] = self.n_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.n_words] = word\n",
        "      self.n_words +=1\n",
        "\n",
        "    else: self.word2count[word] +=1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK04Xfsw6oGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK_2SSo97s2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMiKye9g9QJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "eng_prefix = (\n",
        "    'i am ', 'i m ',\n",
        "    'he is', 'he s',\n",
        "    'she is','she s '\n",
        "    ,'you are', 'you re ',\n",
        "    'we are','we re ',\n",
        "    'they are','they re '\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP8uFHZuER7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefix)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whAZ4nx7Ew62",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "98d16362-f7dc-456f-a27d-753de09bf141"
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "  input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "  print('Read %s sentence pairs'%len(pairs))\n",
        "  pairs = filterPairs(pairs)\n",
        "  print('Trimmed to %s sentence pairs' % len(pairs))\n",
        "  print('Counting words...')\n",
        "  for pair in pairs:\n",
        "    input_lang.addSentence(pair[0])\n",
        "    output_lang.addSentence(pair[1])\n",
        "  print('counting words:')\n",
        "  print(input_lang.name, input_lang.n_words)\n",
        "  print(output_lang.name , output_lang.n_words)\n",
        "  return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng','fra',True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 11066 sentence pairs\n",
            "Counting words...\n",
            "counting words:\n",
            "fra 4601\n",
            "eng 3019\n",
            "['elle est affutee .', 'she is sharp .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J20eqON3Kw0d",
        "colab_type": "text"
      },
      "source": [
        "# encoder\n",
        "![](https://pytorch.org/tutorials/_images/encoder-network.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoFhou5DGYyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(EncoderRNN,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "  \n",
        "  def forward(self,input, hidden):\n",
        "    embedded = self.embedding(input).view(1,1,-1)\n",
        "    output = embedded\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    return output, hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1,1,self.hidden_size,device=device)\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i30KnZ1VK5Sf",
        "colab_type": "text"
      },
      "source": [
        "# decoder\n",
        "![](https://pytorch.org/tutorials/_images/decoder-network.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ymU4ie5KIhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "  \n",
        "  def __init__(self, hidden_size, output_size):\n",
        "    super(DecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "  \n",
        "  def forward(self, input, hidden):\n",
        "    output = self.embedding(input).view(1,1,-1)\n",
        "    output = F.relu(output)\n",
        "    output,hidden = self.gru(output,hidden)\n",
        "    return output, hidden\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1,1, self.hidden_size, device=device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIJzQM6SNj2K",
        "colab_type": "text"
      },
      "source": [
        "# Attention decoder\n",
        "![](https://pytorch.org/tutorials/_images/attention-decoder-network.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXBw6pQQKqUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_size, output_size, dropout_p=0.1,\n",
        "               max_length = MAX_LENGTH):\n",
        "    super(AttnDecoderRNN,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.dropout_p = dropout_p\n",
        "    \n",
        "    self.max_length = max_length\n",
        "    self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "    self.attn = nn.Linear(self.hidden_size *2, self.max_length)\n",
        "    \n",
        "    self.attn_combine = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
        "    self.dropout = nn.Dropout(self.dropout_p)\n",
        "    \n",
        "    self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "    self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "  def forward(self, input, hidden, encoder_outputs):\n",
        "    embedded = self.embedding(input).view(1,1,-1)\n",
        "    embedded = self.dropout(embedded)\n",
        "\n",
        "    attn_weights = F.softmax(\n",
        "        self.attn(torch.cat((embedded[0], hidden[0]),1)),dim=1)\n",
        "    attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                             encoder_outputs.unsqueeze(0))\n",
        "    output = torch.cat((embedded[0], attn_applied[0]),1)\n",
        "    output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "    output = F.relu(output)\n",
        "    output, hidden = self.gru(output,hidden)\n",
        "    output = F.log_softmax(self.out(output[0]),dim=1)\n",
        "    return output,hidden,attn_weights\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1,1,self.hidden_size, device=device)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sraJH_FPSqjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "  return [lang.word2index[word] for word in sentence.split(\" \")]\n",
        "\n",
        "def tensorFromSentence(lang,sentence):\n",
        "  indexes = indexesFromSentence(lang,sentence)\n",
        "  indexes.append(EOS_token)\n",
        "  return torch.tensor(indexes, dtype=torch.long,device=device).view(-1,1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "  input_tensor = tensorFromSentence(input_lang,pair[0])\n",
        "  target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "  return (input_tensor, target_tensor)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNwI2pamYWEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5ruu5WBcB6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "  m = math.floor(s/60)\n",
        "  s -= m* 60\n",
        "  return '%dm %ds' %(m,s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "  now = time.time()\n",
        "  s = now - since\n",
        "  es = s/(percent)\n",
        "  rs = es-s\n",
        "  return \"%s (-%s)\" %(asMinutes(s), asMinutes(rs))\n",
        "  "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSHlS1YKdLhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainIters(encoder,decoder,n_iters,print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "  start = time.time()\n",
        "  plot_losses = []\n",
        "  print_loss_total  = 0 # reset every print_every\n",
        "  plot_loss_total = 0 # reset every plot_every\n",
        "\n",
        "  encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "  decoder_optimizer = optim.SGD(decoder.parameters(),lr=learning_rate)\n",
        "  training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                    for i in range(n_iters)]\n",
        "  criterion = nn.NLLLoss()\n",
        "\n",
        "  for iter in range(1,n_iters + 1):\n",
        "    training_pair = training_pairs[iter-1]\n",
        "    input_tensor = training_pair[0]\n",
        "    target_tensor = training_pair[1]\n",
        "\n",
        "    loss = train(input_tensor, target_tensor, encoder, decoder,\n",
        "                 encoder_optimizer, decoder_optimizer, criterion)\n",
        "    print_loss_total += loss\n",
        "    plot_loss_total += loss\n",
        "\n",
        "    if iter % print_every ==0:\n",
        "      print_loss_avg = print_loss_total / print_every\n",
        "      print_loss_total = 0\n",
        "      print('%s (%d %d%%) %.4f' % (timeSince(start,iter/n_iters),\n",
        "                                   iter, iter/n_iters * 100, print_loss_avg))\n",
        "    if iter % plot_every == 0:\n",
        "      plot_loss_avg = plot_loss_total / plot_every\n",
        "      plot_losses.append(plot_loss_avg)\n",
        "      plot_loss_total = 0\n",
        "\n",
        "\n",
        "  showPlot(plot_losses)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3QOeJqSlDtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "  plt.figure()\n",
        "  fig, ax = plt.subplots()\n",
        "  loc = ticker.MultipleLocator(base=0.2)\n",
        "  ax.yaxis.set_major_locator(loc)\n",
        "  plt.plot(points)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHvXAeAgqp16",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "ff4b0a73-2661-438c-9796-6a15b218c617"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words,dropout_p=0.1).to(device)\n",
        "trainIters(encoder1,attn_decoder1,75000,print_every=5000)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1m 35s (-22m 21s) (5000 6%) 2.9154\n",
            "3m 10s (-20m 35s) (10000 13%) 2.3518\n",
            "4m 42s (-18m 48s) (15000 20%) 2.0462\n",
            "6m 15s (-17m 13s) (20000 26%) 1.8300\n",
            "7m 49s (-15m 39s) (25000 33%) 1.6475\n",
            "9m 23s (-14m 5s) (30000 40%) 1.4664\n",
            "10m 57s (-12m 31s) (35000 46%) 1.2865\n",
            "12m 33s (-10m 59s) (40000 53%) 1.2040\n",
            "14m 7s (-9m 25s) (45000 60%) 1.1033\n",
            "15m 41s (-7m 50s) (50000 66%) 0.9843\n",
            "17m 15s (-6m 16s) (55000 73%) 0.8949\n",
            "18m 50s (-4m 42s) (60000 80%) 0.8257\n",
            "20m 26s (-3m 8s) (65000 86%) 0.7659\n",
            "22m 1s (-1m 34s) (70000 93%) 0.6830\n",
            "23m 38s (-0m 0s) (75000 100%) 0.6536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_Z3sajOsoHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "  with torch.no_grad():\n",
        "    input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "    input_length = input_tensor.size()[0]\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "    for ei in range(input_length):\n",
        "      encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                               encoder_hidden)\n",
        "      decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "      decoder_hidden = encoder_hidden \n",
        "\n",
        "      decoded_words = []\n",
        "      decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "      for di in range(max_length):\n",
        "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "            decoder_input, decoder_hidden, encoder_outputs\n",
        "        )\n",
        "\n",
        "        decoder_attentions[di] = decoder_attention.data\n",
        "        topv, topi = decoder_output.data.topk(1)\n",
        "\n",
        "        if topi.item() == EOS_token:\n",
        "          decoded_words.append(\"<EOS>\")\n",
        "          break\n",
        "        else:\n",
        "          decoded_words.append(output_lang.index2word[topi.item()])\n",
        "        \n",
        "        decoder_input = topi.squeeze().detach()\n",
        "      return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-vgwomJyUMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomly(encoder, decoder,n=10):\n",
        "  for i in range(n):\n",
        "    pair = random.choice(pairs)\n",
        "    print('>', pair[0])\n",
        "    print('=', pair[1])\n",
        "    output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "    output_sentence = ' '.join(output_words)\n",
        "    print('<', output_sentence)\n",
        "    print('')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW6w93m-zF-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "outputId": "1232ae7f-2a7b-42cb-dbb1-477f72d3b724"
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> je fais tout mon possible .\n",
            "= i m doing everything i can .\n",
            "< . <EOS>\n",
            "\n",
            "> c est un artiste celebre .\n",
            "= he is a famous artist .\n",
            "< i m open . <EOS>\n",
            "\n",
            "> nous ne rajeunissons pas .\n",
            "= we re not getting any younger .\n",
            "< we re <EOS>\n",
            "\n",
            "> il s assit pres d elle .\n",
            "= he sat next to her .\n",
            "< he s very sleepy . <EOS>\n",
            "\n",
            "> vous etes l institutrice .\n",
            "= you re the teacher .\n",
            "< i m ready for you . <EOS>\n",
            "\n",
            "> vous etes vraiment genial .\n",
            "= you re really awesome .\n",
            "< i m ready for you . <EOS>\n",
            "\n",
            "> vous etes tellement previsible !\n",
            "= you re so predictable .\n",
            "< i m ready for you . <EOS>\n",
            "\n",
            "> je ne suis pas encore prete .\n",
            "= i am not ready yet .\n",
            "< . <EOS>\n",
            "\n",
            "> j ai tellement soif .\n",
            "= i m so thirsty .\n",
            "< i am . <EOS>\n",
            "\n",
            "> tu es endurant .\n",
            "= you re resilient .\n",
            "< i m completely for . <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-X9pvoxzI2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}